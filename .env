# ============================================
# BLENDER AI AUTOMATION - YOUR CONFIGURATION
# ============================================
# This is your actual .env file - edit with your settings


# ============================================
# AI PROVIDER (CHANGE THIS)
# ============================================

# Current: Using LOCAL LLM (free, runs on your computer)
AI_PROVIDER=local

# To switch to API providers, change to 'claude' or 'openai' and add API key below


# ============================================
# LOCAL LLM SETTINGS (Ollama)
# ============================================

# Ollama API endpoint
LOCAL_LLM_URL=http://localhost:11434/api/generate

# Model name (must be installed: ollama pull codellama)
# Recommended: codellama, deepseek-coder, qwen2.5-coder
LOCAL_LLM_MODEL=llama3.1:8b

# Temperature (0.3-0.5 for code generation)
LOCAL_LLM_TEMPERATURE=0.4

# Max tokens
LOCAL_LLM_MAX_TOKENS=4000


# ============================================
# API KEYS (Optional - only if using Claude/OpenAI)
# ============================================

# Leave empty if using local LLM
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# API Models (only used if AI_PROVIDER is set to claude/openai)
CLAUDE_MODEL=claude-sonnet-4-20250514
OPENAI_MODEL=gpt-4-turbo-preview


# ============================================
# BLENDER PATH (REQUIRED - CHANGE THIS!)
# ============================================

# Linux:
#BLENDER_PATH=E:\Utilz\Blender

# Windows (uncomment and change):
 BLENDER_PATH=E:\Utilz\Blender\blender.exe

# macOS (uncomment and change):
# BLENDER_PATH=/Applications/Blender.app/Contents/MacOS/Blender


# ============================================
# APPLICATION SETTINGS
# ============================================

DEFAULT_MODE=gui
TEMPERATURE=0.4
MAX_TOKENS=4000


# ============================================
# OUTPUT SETTINGS
# ============================================

AUTO_RENDER=false
AUTO_SAVE=true
AUTO_EXPORT=false
EXPORT_FORMAT=obj


# ============================================
# RENDER SETTINGS
# ============================================

RENDER_WIDTH=1920
RENDER_HEIGHT=1080
RENDER_SAMPLES=128
RENDER_ENGINE=CYCLES


# ============================================
# VALIDATION & SAFETY
# ============================================

VALIDATE_CODE=true
SAVE_FAILED_CODE=true
ARCHIVE_GENERATIONS=true
MAX_RETRIES=3


# ============================================
# LOGGING
# ============================================

LOG_LEVEL=INFO
LOG_TO_FILE=true
LOG_FILE=logs/blender_ai.log


# ============================================
# ADVANCED LOCAL LLM (Optional)
# ============================================

LOCAL_LLM_CONTEXT_SIZE=8192
LOCAL_LLM_GPU_LAYERS=-1
LOCAL_LLM_BATCH_SIZE=512
LOCAL_LLM_USE_MMAP=true
LOCAL_LLM_NUM_THREADS=0


# ============================================
# GPU SETTINGS (Optional)
# ============================================

USE_GPU_RENDERING=true
GPU_DEVICE_TYPE=CUDA


# ============================================
# QUICK SETUP GUIDE
# ============================================

# STEP 1: Install Ollama
# Visit: https://ollama.ai/ and download

# STEP 2: Install a code model
# Run: ollama pull codellama

# STEP 3: Start Ollama (if not auto-started)
# Run: ollama serve

# STEP 4: Set your Blender path above

# STEP 5: Test it!
# Run: python src/main.py Create a red cube

# TO SWITCH TO CLAUDE API LATER:
# 1. Get API key from https://console.anthropic.com/
# 2. Change AI_PROVIDER=claude
# 3. Add your key to ANTHROPIC_API_KEY=sk-ant-xxxxx
